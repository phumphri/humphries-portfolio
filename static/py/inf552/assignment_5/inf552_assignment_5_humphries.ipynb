{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preamble():\n",
    "    print(' ')\n",
    "    print('Artificial Neural Networks')\n",
    "    print('Patrick Humphries (pvhumphr@usc.edu)')\n",
    "    print('University of Southern California')\n",
    "    print('INF 552 Machine Learning for Data Science (32458)')\n",
    "    print('Programming Assignment 5')\n",
    "    print('Spring 2020')\n",
    "    print(' ')\n",
    "    print('Due to the large amount of data that was provided')\n",
    "    print('please wait for the first graphic to display.')\n",
    "    print('Canceling the current graphic will allow the next')\n",
    "    print('graphic to be displayed.')\n",
    "    print(' ')\n",
    "    print('In order to calculate the best accuracy with the')\n",
    "    print('minimum weight values, all 1,000 iterations are run.')\n",
    "    print('When the program is done, \"Done!\" will be displayed.')\n",
    "    print(' ')\n",
    "    print('keras with tensorflow is run as the final step.  If')\n",
    "    print('packages have not been stalled, then the final step')\n",
    "    print('will fail.  If this happens, consider \"pip install tesorflow\"')\n",
    "    print('\"pip install keras\" if running python.  If running Jupyter')\n",
    "    print('Notebook, consider adding two cells.  One for')\n",
    "    print('\"conda install tensorflow\" and one for \"conda install keras\".')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n Importing libraries.')\n",
    "import os\n",
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_paths(file_name='downgesture_train.list.txt'):\n",
    "    '''\n",
    "    Return a list of file paths from a file of file paths.\n",
    "    For this assignment, this function will be called twice.\n",
    "    Once for training samples and again for testing samples.\n",
    "    '''\n",
    "    print('\\t Getting file paths.')\n",
    "    \n",
    "    file_paths = []\n",
    "    \n",
    "    with open(file_name, 'r') as f:\n",
    "        for line in f:\n",
    "            file_paths.append(line.strip())\n",
    "            \n",
    "    return file_paths\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_samples(target_file_names='downgesture_train.list.txt', number_of_files=1000):\n",
    "    '''\n",
    "    Create a vector of samples and a vector of samples that \n",
    "    correspond to the samples.  \n",
    "    \n",
    "    For Homework 5, the pixel values specified ranged from 0\n",
    "    to 1.  The file has the range from 0 to 255.  Hence, this\n",
    "    function scales the values down by dividing by 255.\n",
    "    '''\n",
    "    print('\\t Building samples and labels.')\n",
    "    \n",
    "    # Define containers for samples and labels.\n",
    "    samples = []\n",
    "    labels = []\n",
    "    \n",
    "    # Process each image file.\n",
    "    file_paths = get_file_paths(target_file_names)\n",
    "    file_number = 0\n",
    "    for file_path in file_paths:\n",
    "        file_number += 1\n",
    "        if file_number > number_of_files:\n",
    "            break\n",
    "        # Get a numpy array organized by rows and columns.\n",
    "        # Need to copy the original array because it is read only.\n",
    "        sample = np.array(plt.imread(file_path,format='PGM'))\n",
    "        \n",
    "        # Scale sample from native (0,255) to (0,1) per requirements.\n",
    "        sample = sample / 255\n",
    "        \n",
    "        # Add the sample to the collection of samples.\n",
    "        samples.append(sample)\n",
    "        \n",
    "        # Get label value based on file name.\n",
    "        file_path = file_path.lower()\n",
    "        if file_path.find('down') == -1:\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "\n",
    "    # Return samples and corresponding labels.\n",
    "    return samples, labels\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(start, samples, labels, rows=5, columns=5):\n",
    "    '''\n",
    "    Display 25 images in a 5x5 visualization using a grey colormap.\n",
    "    '''\n",
    "    print('\\t Visualizing images.')\n",
    "    \n",
    "    # Determine if using \"monokai\" on the development workstation\n",
    "    # or default context on grader's workstation.\n",
    "    logon_server = os.environ[\"LOGONSERVER\"]\n",
    "    \n",
    "    if logon_server.find('XPS') == -1:\n",
    "        r = plt.rcdefaults()\n",
    "    else:\n",
    "        r = {\"axes.edgecolor\":\"yellow\",\n",
    "             \"axes.labelcolor\":\"yellow\", \n",
    "             \"xtick.color\":\"yellow\", \n",
    "             \"ytick.color\":\"yellow\",\n",
    "             \"figure.facecolor\":(0.18, 0.31, 0.32)}\n",
    "\n",
    "    with plt.rc_context(r):    \n",
    "        gridspec_kw = {\"hspace\":0.1, \"wspace\":0.1}\n",
    "\n",
    "        fig, ax = plt.subplots(rows, columns, figsize=(30,32),\n",
    "                               subplot_kw={'xticks':[],'yticks':[]},\n",
    "                               gridspec_kw = gridspec_kw) \n",
    "\n",
    "        sample_number = 0\n",
    "        for images_row in range(rows):\n",
    "            for images_column in range(columns):\n",
    "                sample = samples[sample_number]\n",
    "                ax[images_row][images_column].imshow(sample, cmap='Greys')\n",
    "                s = str(start + sample_number + 1) + ':' + str(labels[sample_number])\n",
    "                ax[images_row][images_column].text(2, 5, s, fontsize=28, color ='red')\n",
    "                sample_number += 1\n",
    "                \n",
    "        plt.show() \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_images(samples, margin = 16):\n",
    "    '''\n",
    "    To have weights calculated consistently, the foreground needs\n",
    "    to be lighter than the background.  If the background is darker,\n",
    "    the image is reversed.\n",
    "    '''\n",
    "    print('\\t Reversing images.')\n",
    "    \n",
    "    # Each image consists of 30 rows and 32 columns of \n",
    "    # integer numbers representing pixel shading.\n",
    "    rows = 30\n",
    "    cols = 32\n",
    "\n",
    "    for i in range(len(samples)):\n",
    "        \n",
    "        sample = samples[i]\n",
    "        \n",
    "        # This pixel is consideered the background value.\n",
    "        left_pixel = sample[15][0]\n",
    "        \n",
    "        # This pixel is considered the forground value.\n",
    "        center_pixel = sample[14][15]\n",
    "        \n",
    "        # Reverse the image if background is darker than the forground.\n",
    "        if left_pixel > center_pixel:\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    sample[row][col] = 1 - sample[row][col]\n",
    "        \n",
    "        # Make background white and forgraund black.\n",
    "        if False:\n",
    "            center_pixel = sample[14][15]\n",
    "\n",
    "            low_end = center_pixel - margin\n",
    "            if low_end < 0:\n",
    "                low_end = 0\n",
    "            high_end = center_pixel + margin\n",
    "            if high_end > 255:\n",
    "                high_end = 255\n",
    "\n",
    "            # Convert pixels to binary values.\n",
    "            for row in range(rows):\n",
    "                for col in range(cols):\n",
    "                    p = sample[row][col]\n",
    "                    if p > low_end and p < high_end:\n",
    "                        sample[row][col] = 0\n",
    "                        pass\n",
    "                    else:\n",
    "                        sample[row][col] = 0\n",
    "                    \n",
    "    return samples\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_weights():\n",
    "    '''\n",
    "    There 9 weights per activation, and there are 100 activations.\n",
    "    This function creates the weights with default values between\n",
    "    -0.01 an 0.01\n",
    "    '''\n",
    "    print('\\t Building weights.')\n",
    "    \n",
    "    # The number of activations:  The middle layer.\n",
    "    j = 100\n",
    "    \n",
    "    # The number of pixels in the input layer and weights vector.\n",
    "    k = 9\n",
    "    \n",
    "    # Create random weights from 0 to 1.\n",
    "    weights = np.random.random_sample((j,k))\n",
    "    \n",
    "    # Double the weights from 0 to 2.\n",
    "    weights = weights * 2\n",
    "    \n",
    "    # Shift the weights from -1 to 1.\n",
    "    weights = weights - 1\n",
    "    \n",
    "    # Scale down by 100, resulting in values -0.01 through 0.01.\n",
    "    weights = weights / 100\n",
    "    \n",
    "    return weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build(target_file_names='downgesture_train.list.txt', number_of_files=1000):\n",
    "    '''\n",
    "    Build the model consisting of initialized weights and biases.  \n",
    "    \n",
    "    Also, build the sample array and labels needed to train the model.\n",
    "    '''\n",
    "    print('\\t Building samples, weights, biases, and labels.')\n",
    "    \n",
    "    samples, labels = build_samples(target_file_names, number_of_files)\n",
    "    \n",
    "    # View sample images before making foreground darker than background. \n",
    "    if True:\n",
    "        start = 0\n",
    "        end = start + 25\n",
    "        visualize_images(start, samples[start:end], labels[start:end])\n",
    "\n",
    "    # Make the foreground darker than the background.\n",
    "    samples = reverse_images(samples)\n",
    "\n",
    "    # View sample images after making foreground darker than background.\n",
    "    if True:\n",
    "        start = 0\n",
    "        end = start + 25\n",
    "        visualize_images(start, samples[start:end], labels[start:end])\n",
    "\n",
    "    # Visualize all samples.\n",
    "    if False:\n",
    "        for start in range(0, len(samples), 25):\n",
    "            end = start + 25\n",
    "            if end > len(samples) - 1:\n",
    "                end = len(samples) - 1\n",
    "                start = end - 25\n",
    "            visualize_images(start, samples[start:end], labels[start:end])\n",
    "\n",
    "    # Define weights.\n",
    "    weights = build_weights()\n",
    "    \n",
    "    # Define biases.\n",
    "    biases = np.zeros(100,)\n",
    "     \n",
    "    return (samples, weights, biases, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(samples, weights, biases, labels, iterations=1001):\n",
    "    '''\n",
    "    Train the model with training samples and labels.\n",
    "    '''\n",
    "    print('\\t Fitting weights and biases.')\n",
    "    \n",
    "    # Define number of samples.\n",
    "    m = len(samples)\n",
    "    \n",
    "    # Define number of activations.\n",
    "    n = 100\n",
    "    \n",
    "    # Define biases.\n",
    "    b = biases\n",
    "    \n",
    "    # Define total cost.\n",
    "    C = 0.0\n",
    "    \n",
    "    # Proces iterations.\n",
    "    for h in range(iterations):\n",
    "        \n",
    "        # Define cost of the iteration.\n",
    "        Ch = 0.0\n",
    "        \n",
    "        # Define variable for calculating the accuracy of the iteration.\n",
    "        correct = 0\n",
    "        count = 0\n",
    "\n",
    "        # Process samples.\n",
    "        for i in range(m):\n",
    "               \n",
    "            # Define sample cost.\n",
    "            Ci = 0.0\n",
    "    \n",
    "            # Define activation vector.\n",
    "            a = np.zeros(n,)\n",
    "            \n",
    "            # Process activations.\n",
    "            for j in range(n):\n",
    "\n",
    "                # Load pixel vector.\n",
    "                p = np.zeros(9,)\n",
    "                row = ((math.ceil((j + 1) / 10)) * 3) - 3\n",
    "                col = ((j + 1) * 3 - 1) - (row * 10)\n",
    "                p[0] = samples[i][row][col]\n",
    "                p[1] = samples[i][row][col + 1]\n",
    "                p[2] = samples[i][row][col + 2]\n",
    "                p[3] = samples[i][row + 1][col]\n",
    "                p[4] = samples[i][row + 1][col + 1]\n",
    "                p[5] = samples[i][row + 1][col + 2]\n",
    "                p[6] = samples[i][row + 2][col]\n",
    "                p[7] = samples[i][row + 2][col + 1]\n",
    "                p[8] = samples[i][row + 2][col + 2]\n",
    "\n",
    "                # load weight vector.\n",
    "                w = np.zeros(9,)\n",
    "                for k in range(9):\n",
    "                    w[k] = weights[j][k]\n",
    "\n",
    "                # Calculate dot product of weights and pixels.\n",
    "                a[j] = w@p\n",
    "                \n",
    "                # Calculate the probability.\n",
    "                try:\n",
    "                    a[j] = math.exp(a[j])/(math.exp(a[j]) + 1)\n",
    "                except OverflowError as e:\n",
    "                    print('OverflowError:', e, 'a[' + str(j) +']:', a[j])\n",
    "                    print('h:', h, 'i:', i, 'j:', j)\n",
    "                    print('w:', w)\n",
    "                    print('p:', p)\n",
    "                    print('labels:', labels)\n",
    "                    break\n",
    "                \n",
    "                # Apply bias.\n",
    "                a[j] = a[j] + b[j]\n",
    "\n",
    "            # Calculate output by averaging activations.\n",
    "            o = np.average(a)\n",
    "            \n",
    "            # Subtract 0.5 so the input of the output sigmoid\n",
    "            # is 0.5 when the input is zero.\n",
    "            o -= 0.5\n",
    "            \n",
    "            # Calculate the probability of the output.\n",
    "            o = math.exp(o)/(math.exp(o) + 1)\n",
    "            \n",
    "            # Make a decision based on probability.\n",
    "            if o >= 0.5:\n",
    "                o = 1\n",
    "            else:\n",
    "                o = 0\n",
    "\n",
    "            # Get the target for the cost calculation.\n",
    "            y = labels[i]\n",
    "            \n",
    "            # Accumulate values for initial accuracy.\n",
    "            count += 1\n",
    "            if y == o:\n",
    "                correct += 1\n",
    "\n",
    "            # Debug misses.\n",
    "            if False:\n",
    "                if y == o:\n",
    "                    correct += 1\n",
    "                    print(' ')\n",
    "                    if o == 0:\n",
    "                        print('=== Hit on False ===')\n",
    "                    else:\n",
    "                        print('=== Hit on True ===')\n",
    "                else:\n",
    "                    if o == 1:\n",
    "                        print('xxx Miss on False xxx')\n",
    "                    else:\n",
    "                        print('xxx Miss on True xxx')\n",
    "                        print('h:', h, 'i:', i, 'y:', y, 'o:', o, 'avg:', np.average(a))\n",
    "                        print(a)\n",
    "\n",
    "            # Calculate iteration cost.\n",
    "            Ci = (y - o)**2\n",
    "            \n",
    "            # Aggregate iteration cost and total cost.\n",
    "            Ch += Ci\n",
    "            C += Ci\n",
    "\n",
    "            # Increment is the difference between label and output.\n",
    "            C = (y - o)\n",
    "            \n",
    "            # Apply the learning rate to the increment.\n",
    "            C = C * 0.1\n",
    "            \n",
    "            # Apply the increment to each weight scaled by the pixel value.\n",
    "            for j in range(n):\n",
    "                # Load pixel vector.\n",
    "                p = np.zeros(9,)\n",
    "                row = ((math.ceil((j + 1) / 10)) * 3) - 3\n",
    "                col = ((j + 1) * 3 - 1) - (row * 10)\n",
    "                p[0] = samples[i][row][col]\n",
    "                p[1] = samples[i][row][col + 1]\n",
    "                p[2] = samples[i][row][col + 2]\n",
    "                p[3] = samples[i][row + 1][col]\n",
    "                p[4] = samples[i][row + 1][col + 1]\n",
    "                p[5] = samples[i][row + 1][col + 2]\n",
    "                p[6] = samples[i][row + 2][col]\n",
    "                p[7] = samples[i][row + 2][col + 1]\n",
    "                p[8] = samples[i][row + 2][col + 2]\n",
    "                \n",
    "                # Adjust weights, but keep in original range of -0.01 to 0.01\n",
    "                for k in range(9):\n",
    "                    weights[j][k] = weights[j][k] + C*p[k]\n",
    "                    if weights[j][k] > 0.01:\n",
    "                        weights[j][k] = 0.01\n",
    "                    elif weights [j][k] < -0.01:\n",
    "                        weights[j][k] = -0.01\n",
    "                        \n",
    "        if h % 100 == 0:             \n",
    "            print('\\t iteration:', h, 'count:', count, 'correct:', correct, 'rate:',\n",
    "                  round(correct/count, 2), 'cost:', Ch)\n",
    "                        \n",
    "    return (weights, biases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sample, weights, biases):\n",
    "    '''\n",
    "    Make a prediction of a sample image based on trained\n",
    "    weights and biases.\n",
    "    '''\n",
    "    # Define number of samples.\n",
    "    m = len(samples)\n",
    "    \n",
    "    # Define number of activations.\n",
    "    n = 100\n",
    "    \n",
    "    # Define biases.\n",
    "    b = biases\n",
    "    \n",
    "    # Define activation vector.\n",
    "    a = np.zeros(n,)\n",
    "\n",
    "    # Process activations.\n",
    "    for j in range(n):\n",
    "\n",
    "        # Load pixel vector.\n",
    "        p = np.zeros(9,)\n",
    "        row = ((math.ceil((j + 1) / 10)) * 3) - 3\n",
    "        col = ((j + 1) * 3 - 1) - (row * 10)\n",
    "        p[0] = sample[row][col]\n",
    "        p[1] = sample[row][col + 1]\n",
    "        p[2] = sample[row][col + 2]\n",
    "        p[3] = sample[row + 1][col]\n",
    "        p[4] = sample[row + 1][col + 1]\n",
    "        p[5] = sample[row + 1][col + 2]\n",
    "        p[6] = sample[row + 2][col]\n",
    "        p[7] = sample[row + 2][col + 1]\n",
    "        p[8] = sample[row + 2][col + 2]\n",
    "\n",
    "        # load weight vector.\n",
    "        w = np.zeros(9,)\n",
    "        for k in range(9):\n",
    "            w[k] = weights[j][k]\n",
    "\n",
    "        # Calculate dot product of weights and pixels.\n",
    "        a[j] = w@p\n",
    "\n",
    "        # Calculate the probability.\n",
    "        try:\n",
    "            a[j] = math.exp(a[j])/(math.exp(a[j]) + 1)\n",
    "        except OverflowError as e:\n",
    "            print('OverflowError:', e, 'a[' + str(j) +']:', a[j])\n",
    "            print('h:', h, 'i:', i, 'j:', j)\n",
    "            print('w:', w)\n",
    "            print('p:', p)\n",
    "            print('labels:', labels)\n",
    "            break\n",
    "\n",
    "        # Apply bias.\n",
    "        a[j] = a[j] + b[j]\n",
    "\n",
    "    # Calculate output by averaging activations.\n",
    "    o = np.average(a)\n",
    "\n",
    "    # Subtract 0.5 so the input of the output sigmoid\n",
    "    # is 0.5 when the input is zero.\n",
    "    o -= 0.5\n",
    "\n",
    "    # Calculate the probability of the output.\n",
    "    o = math.exp(o)/(math.exp(o) + 1)\n",
    "\n",
    "    # Make a decision based on probability.\n",
    "    if o >= 0.5:\n",
    "        o = 1\n",
    "    else:\n",
    "        o = 0\n",
    "    \n",
    "    # Return the decision.\n",
    "    return o\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(weights, biases, target_file_names='downgesture_test.list.txt'):\n",
    "    '''\n",
    "    Calculate the rate of correct decisions given trained weights, biases,\n",
    "    and a list of testing samples.\n",
    "    '''\n",
    "    # Define scoring counters.\n",
    "    count = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # Build vectors of samples and labels.\n",
    "    samples, labels = build_samples(target_file_names)\n",
    "\n",
    "    # View sample images before making foreground darker than background. \n",
    "    if False:\n",
    "        start = 0\n",
    "        end = start + 25\n",
    "        visualize_images(start, samples[start:end], labels[start:end])\n",
    "\n",
    "    # Make the foreground darker than the background.\n",
    "    samples = reverse_images(samples)\n",
    "\n",
    "    # Make a decision for each sample.\n",
    "    for i in range(len(samples)):\n",
    "        count += 1\n",
    "        o = predict(samples[i], weights, biases)\n",
    "        y = labels[i]\n",
    "        if y == o:\n",
    "             correct += 1\n",
    "\n",
    "    # Return the scoring counters.\n",
    "    return (count, correct)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_keras_with_tensorflow():\n",
    "    '''\n",
    "    This function required the intallation of keras and tensorflow packages.\n",
    "    If this function fails, consider loading these packages and run again.\n",
    "    '''\n",
    "    from keras import backend as K\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Activation\n",
    "    from keras.layers.core import Dense\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.metrics import categorical_crossentropy\n",
    "\n",
    "    # Build vectors of samples and labels.\n",
    "    training_samples, training_labels = build_samples('downgesture_train.list.txt')\n",
    "    testing_samples, testing_labels = build_samples('downgesture_test.list.txt')\n",
    "\n",
    "    # Reshaping the training data to be a two-dimensional vector.\n",
    "    training_samples = np.array(training_samples)\n",
    "    training_samples.resize(len(training_samples),960)\n",
    "    training_labels = np.array(training_labels)\n",
    "\n",
    "    # Reshaping the testing data to be a two-dimensionaal vector.\n",
    "    testing_samples = np.array(testing_samples)\n",
    "    testing_samples.resize(len(testing_samples),960)\n",
    "    testing_labels = np.array(testing_labels)\n",
    "\n",
    "    # Build model.\n",
    "    model = Sequential([\n",
    "        Dense(100, input_shape=(960,)),\n",
    "        Dense(10, activation='relu'),\n",
    "        Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Display model structure.\n",
    "    print('\\n Model summary.')\n",
    "    model.summary()\n",
    "\n",
    "    # Configure model.\n",
    "    model.compile(Adam(lr=0.1), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train and test model.\n",
    "    print('\\n Training model.')\n",
    "    model.fit(training_samples, training_labels, batch_size=10, epochs=8, shuffle=False)\n",
    "    \n",
    "    # Make predictions.\n",
    "    print('\\n Testing model.')\n",
    "    predictions = model.predict_classes(testing_samples, batch_size=10)\n",
    "    \n",
    "    # Compare predictions to labels.\n",
    "    count = len(testing_labels)\n",
    "    correct = 0\n",
    "    for i in range(len(testing_labels)):\n",
    "        if predictions[i] == testing_labels[i]:\n",
    "            correct += 1\n",
    "    \n",
    "    print('count:', count, 'correct:', correct, 'rate:', round(correct/count, 2))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Main\n",
    "'''\n",
    "This is the main routine from where all major functions are called.\n",
    "'''\n",
    "# Display identification information.\n",
    "preamble()\n",
    "print('\\n Starting main.')\n",
    "\n",
    "# Build model.\n",
    "print('\\n Building model.')\n",
    "samples, weights, biases, labels = build()\n",
    "\n",
    "# Train model.\n",
    "print('\\n Training model.')\n",
    "weights, biases = fit(samples, weights, biases, labels)\n",
    "\n",
    "# Test model.\n",
    "print('\\n Scoring model.')\n",
    "count, correct = score(weights, biases)\n",
    "print('\\t count:', count, 'correct:', correct, 'rate:', round(correct/count, 2))\n",
    "\n",
    "# Software familiarization with keras and tensor flow.\n",
    "print('\\n Executing keras with tensorflow.')\n",
    "print('\\t If this step should fail, check if keras and tensorflow are installed.')\n",
    "run_keras_with_tensorflow()\n",
    "\n",
    "print('\\n Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
