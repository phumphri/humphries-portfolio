{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('Importing libraries.')\n",
    "\n",
    "\n",
    "import os\n",
    "os.system(\"python -m pip install seaborn\")\n",
    "os.system(\"python -m pip install sklearn\")\n",
    "os.system(\"python -m pip install sklearn.metrics\")\n",
    "os.system(\"python -m pip install sklearn.metrics.plot_confusion_matrix\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from sklearn.manifold import Isomap\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preamble():\n",
    "    print(' ')\n",
    "    print('Class Project')\n",
    "    print(' ')\n",
    "    print('Learning Computer Vision Fundamentals with the Famous MNIST Data')\n",
    "    print(' ')\n",
    "    print('Patrick Humphries (pvhumphr@usc.edu)')\n",
    "    print('University of Southern California')\n",
    "    print('INF 552 Machine Learning for Data Science (32458)')\n",
    "    print('Final Project')\n",
    "    print('Spring 2020')\n",
    "    print(' ')\n",
    "    print('Due to the large amount of data that was provided')\n",
    "    print('please wait for the first graphic to display.')\n",
    "    print('Canceling the current graphic will allow the next')\n",
    "    print('graphic to be displayed.')\n",
    "    print(' ')\n",
    "    print('When the program is done, \"Done!\" will be displayed.')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_features_to_two_dimensions(features):\n",
    "    '''\n",
    "    The Isomap reduces the dimensionality of the features from\n",
    "    784 to 2.  This allows the visualize_features function to\n",
    "    visualize the data in two dimensions.\n",
    "    '''\n",
    "    isomap = Isomap(n_components = 2)\n",
    "    isomap.fit(features.data)\n",
    "    transformed_features = isomap.transform(features.data)\n",
    "    \n",
    "    return transformed_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt.rcParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_name, skip_header, max_rows, test_size=0.25):\n",
    "    '''\n",
    "    The label is in column 0. Features are in columns 1 through 784.\n",
    "    These columns are the flatten version of 28x28 pixel image.\n",
    "\n",
    "    Load the attributes into vector features, which contains 784 columns.\n",
    "    \n",
    "    Load the labels into vector labels from column 0.\n",
    "    \n",
    "    Return features and labels.\n",
    "    '''\n",
    "    # Load trining dataset.\n",
    "    path_to_csv = 'digit-recognizer' + os.path.sep + file_name\n",
    "    \n",
    "    # Load features\n",
    "    usecols = range(1,785)\n",
    "    X = np.genfromtxt(path_to_csv, dtype=int, skip_header=skip_header, delimiter=',', \\\n",
    "                      usecols=usecols, max_rows=max_rows)\n",
    "\n",
    "    # Scale features from 0 through 256 to 0 through 1.\n",
    "    X = X / 256\n",
    "\n",
    "    # Load labels\n",
    "    y = np.genfromtxt(path_to_csv, dtype=int, skip_header=skip_header, delimiter=',', \\\n",
    "                      usecols=0, max_rows=max_rows)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    print('X_train.shape:', X_train.shape, 'y_train.shape:', y_train.shape, \\\n",
    "         'X_test.shape:', X_test.shape, 'y_test.shape:', y_test.shape)\n",
    "    \n",
    "    return (X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_context():\n",
    "    '''\n",
    "    The development environment (XPS) uses \"monokai\" theme,\n",
    "    which is dark.  It is unknown what environment is used\n",
    "    by the grader, so it reverts to default.\n",
    "    '''\n",
    "    logon_server = os.environ[\"LOGONSERVER\"]\n",
    "    \n",
    "    if logon_server.find('XPX') == -1:\n",
    "        plt.rcdefaults()\n",
    "        r = plt.rcParams\n",
    "    else:\n",
    "        r = {\"axes.edgecolor\":global_text_color,\n",
    "             \"axes.labelcolor\":global_text_color,\n",
    "             \"axes.facecolor\":global_face_color,\n",
    "             \"xtick.color\":global_text_color, \n",
    "             \"ytick.color\":global_text_color,\n",
    "             \"text.color\":global_text_color,\n",
    "             \"figure.facecolor\":global_face_color}\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_features(features, labels, title, alpha=1.0):\n",
    "    '''\n",
    "    Provide the user with a two-dimensional visualization of\n",
    "    the data.  This will allow the user to better understand\n",
    "    the covariance of the data and select the appropriate\n",
    "    models.\n",
    "    '''\n",
    "    # When using the integer labels, ensure they are \n",
    "    # converted to floats for color rendering.\n",
    "    c = labels[:]\n",
    "    c = c * (1.0)\n",
    "\n",
    "    # Determine display context.\n",
    "    r = determine_context()\n",
    "    \n",
    "    # Plot the two-dimensional features using the\n",
    "    # selected context.\n",
    "    with plt.rc_context(r):\n",
    "        plt.figure(figsize=(7.0,5.0))\n",
    "        x = features[:,0]\n",
    "        y = features[:,1]            \n",
    "        plt.scatter(x, y, cmap=\"tab10\", c=c, alpha=alpha)\n",
    "        plt.title(title)        \n",
    "        plt.colorbar(label='Digit', ticks=range(0,10))        \n",
    "        plt.clim(-0.5, 9.5)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isomap_for_all_digits(features, labels):\n",
    "    '''\n",
    "    Visualize the 784-feature dataset as a two-dimensional isomap.\n",
    "    '''\n",
    "    # Reduce the number of features to two and display.\n",
    "    reduced_features = reduce_features_to_two_dimensions(features)\n",
    "\n",
    "    # Visualize the transformed data.\n",
    "    title = 'All Figures in Isomap Dimensions'\n",
    "    visualize_features(reduced_features, labels, title)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_heatmap(testing_labels, testing_model, title, annot=True):\n",
    "    '''\n",
    "    Accuracy can be determined by the number of correct answers versus\n",
    "    total answers.  However, that is just a single number.  A heatmap\n",
    "    shows which estimates are in error and the type of error.\n",
    "    '''\n",
    "    # Calculate the confustion matrix that compares testing labels\n",
    "    # to predicted labels via a testing model.\n",
    "    cm = confusion_matrix(testing_labels, testing_model)\n",
    "    \n",
    "    # Determine display context.\n",
    "    r = determine_context()\n",
    "    \n",
    "    # Plot the heatmap using the selected context.\n",
    "    with plt.rc_context(r):  \n",
    "        plt.figure(figsize=(6.0,6.0))\n",
    "        sns.heatmap(cm, square=True, annot=annot, cbar=True)\n",
    "        plt.xlabel('Predicted Value')\n",
    "        plt.ylabel('True Value')\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_scores(model_scores):\n",
    "    '''\n",
    "    Compare the model scores using a horizontal bar chart.\n",
    "    '''\n",
    "    # Decompose the the scores from a dictionary to\n",
    "    # two lists:  model names and model scores.\n",
    "    model_names = list(model_scores.keys())\n",
    "    model_scores = list(model_scores.values())\n",
    "\n",
    "    # Determine display context.\n",
    "    r = determine_context()\n",
    "    \n",
    "    # Plot the scores using the selected \n",
    "    with plt.rc_context(r):  \n",
    "        ax = plt.axes()\n",
    "        ax.barh(model_names, model_scores)\n",
    "        ax.set_xlabel('Model Score')\n",
    "        ax.set_title('Comparing Model Scores')\n",
    "        \n",
    "        # Add the scores to the horizontal bars.\n",
    "        for i, v in enumerate(model_scores):\n",
    "            ax.text(v - 0.08, i, str(round(v,2)),  fontweight='bold', color='white')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_params(params):\n",
    "    \n",
    "    # Define column labels.\n",
    "    colLabels = ('param', 'value')\n",
    "    \n",
    "    # Define cell texts.\n",
    "    cellTexts = []\n",
    "    for key, value in params.items():\n",
    "        cellText = [key, value]\n",
    "        cellTexts.append(cellText)\n",
    "        cellColors = []\n",
    "        \n",
    "    # Determine display context.\n",
    "    r = determine_context()\n",
    "\n",
    "    # Plot the scores using the selected \n",
    "    with plt.rc_context(r):  \n",
    "    \n",
    "        fig, ax = plt.subplots(figsize=[6.0, 4.0])\n",
    "\n",
    "        # Hide axes.\n",
    "        ax.axis('off')\n",
    "\n",
    "        # Build table\n",
    "        if r[\"text.color\"] == global_text_color:\n",
    "            \n",
    "            # Set cell colors.\n",
    "            for i in range(len(cellTexts)):\n",
    "                cellColor = []\n",
    "                for j in range(len(cellTexts[i])):\n",
    "                    cellColor.append(global_face_color)\n",
    "                cellColors.append(cellColor)\n",
    "\n",
    "            # Set column colors\n",
    "            colColors = [global_face_color, global_face_color]\n",
    "\n",
    "            the_table = ax.table(cellText = cellTexts, colLabels = colLabels,\n",
    "                                 loc='center', cellColours=cellColors, colColours=colColors)\n",
    "        else:\n",
    "            the_table = ax.table(cellText = cellTexts, colLabels = colLabels, loc='center')\n",
    "            \n",
    "        the_table.auto_set_font_size(False)\n",
    "        the_table.set_fontsize(14)\n",
    "        \n",
    "        # Visualize table.\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_images(rows = 5, columns = 5):\n",
    "    '''\n",
    "    Visualize the first twenty-five characters so the\n",
    "    user can understand the nature of the data.\n",
    "    '''\n",
    "    \n",
    "    file_name = 'train.csv'\n",
    "    skip_header = 1\n",
    "    max_rows = rows * columns\n",
    "    test_size = 0.50\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = load_data(file_name, skip_header, max_rows * 2, test_size)\n",
    "\n",
    "    # Determine display context.\n",
    "    r = determine_context()\n",
    "    \n",
    "    # Plot the 28x28 characters in a grid that is 5x5.\n",
    "    with plt.rc_context(r):    \n",
    "        images = X_train.reshape(max_rows, 28, 28)\n",
    "        gridspec_kw = {\"hspace\":0.1, \"wspace\":0.1}\n",
    "\n",
    "        fig, ax = plt.subplots(rows, columns, figsize=(28,28),\n",
    "                               subplot_kw={'xticks':[],'yticks':[]},\n",
    "                               gridspec_kw = gridspec_kw) \n",
    "\n",
    "        image_number = 0\n",
    "        for images_row in range(rows):\n",
    "            for images_column in range(columns):\n",
    "                ax[images_row][images_column].imshow(images[image_number], cmap='Greys')\n",
    "                ax[images_row][images_column].text(2,5,\n",
    "                                                   str(y_train[image_number]),\n",
    "                                                   fontsize=28,\n",
    "                                                   color='red')\n",
    "                image_number += 1\n",
    "                \n",
    "        plt.show()        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_Mixture_Model(X_train, y_train, X_test, y_test, max_iter):\n",
    "    '''\n",
    "    Isomap demonstrated that the data is distributed in overlaping groups.\n",
    "    Therefore, samples should be allocated to digit based on a\n",
    "    Gaussian distribution.\n",
    "    '''\n",
    "    n_components = 10\n",
    "    model = GaussianMixture(n_components = n_components, max_iter = max_iter)\n",
    "    classifier = model.fit(X_train, y_train)\n",
    "    testing_model = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, testing_model)\n",
    "#     cv_scores = cross_val_score(classifier, X_test, y_test, cv = 3)\n",
    "\n",
    "    print(' ')\n",
    "    print('===== Gaussian Mixture Model =====')\n",
    "    print('score:', score)\n",
    "#     print('cross validation scores:', cv_scores)\n",
    "    \n",
    "    # Visualize parameters in a table.\n",
    "    visualize_params(model.get_params())\n",
    "    \n",
    "    # Visualize actual labels versus predicted labels.\n",
    "    visualize_heatmap(y_test, testing_model, 'Gaussian Mixture Model')    \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_Naive_Bayes_Model(X_train, y_train, X_test, y_test):\n",
    "    '''\n",
    "    Isomap demonstrated that the data is distributed in overlaping groups.\n",
    "    Therefore, samples should be allocated to digit based on a\n",
    "    Gaussian distribution.\n",
    "    '''\n",
    "    model = GaussianNB()\n",
    "    classifier = model.fit(X_train, y_train)\n",
    "    testing_model = model.predict(X_test)\n",
    "    score = model.score(X_test, y_test)\n",
    "    cv_scores = cross_val_score(classifier, X_test, y_test, cv = 3)\n",
    "\n",
    "    print(' ')\n",
    "    print('===== Gaussian Naive Bayes Model =====')\n",
    "    print('score:', score)\n",
    "    print('cross validation scores:', cv_scores)\n",
    "    \n",
    "    # Visualize parameters in a table.\n",
    "    visualize_params(model.get_params())\n",
    "    \n",
    "    # Display confusion matrix.\n",
    "    visualize_heatmap(y_test, testing_model, 'Gaussian Naive Bayes')        \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_Tree_Model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    model = DecisionTreeClassifier()\n",
    "    classifier = model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    testing_model = model.predict(X_test)\n",
    "    cv_scores = cross_val_score(classifier, X_test, y_test, cv = 3)\n",
    "        \n",
    "    print(' ')\n",
    "    print('===== Decision Tree Model =====')\n",
    "    print('score:', score)\n",
    "    print('cross validation scores:', cv_scores) \n",
    "      \n",
    "    # Visualize parameters in a table.\n",
    "    visualize_params(model.get_params())\n",
    "    \n",
    "    # Display confusion matrix.\n",
    "    visualize_heatmap(y_test, testing_model, 'Decision Tree Model')       \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNeighbors_Model(X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    k = 1\n",
    "    max_score = 0.0\n",
    "    testing_model = None\n",
    "    cv_scores = None\n",
    "    \n",
    "    for n_neighbors in  range(1,4):\n",
    "        \n",
    "        model = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "        classifier = model.fit(X_train, y_train)\n",
    "        testing_model = model.predict(X_test)\n",
    "        score = model.score(X_test, y_test)\n",
    "\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            k = n_neighbors\n",
    "            cv_scores = cross_val_score(classifier, X_test, y_test, cv = 3)\n",
    "               \n",
    "    print(' ')\n",
    "    print('===== k-Neighbors Model =====')\n",
    "    print('score:', max_score)\n",
    "    print('cross validation scores:', cv_scores) \n",
    "      \n",
    "    # Visualize parameters in a table.\n",
    "    visualize_params(model.get_params())\n",
    "    \n",
    "    # Display confusion matrix.\n",
    "    visualize_heatmap(y_test, testing_model, 'k-Neighbors')     \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPClassifier_Model(X_train, y_train, X_test, y_test, max_iter):\n",
    "    \n",
    "    model = MLPClassifier(max_iter = max_iter)\n",
    "    classifier = model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    testing_model = model.predict(X_test)\n",
    "    cv_scores = cross_val_score(classifier, X_test, y_test, cv = 3)\n",
    "        \n",
    "    print(' ')\n",
    "    print('===== MLP Classifier Model =====')\n",
    "    print('score:', score)\n",
    "    print('cross validation scores:', cv_scores) \n",
    "      \n",
    "    # Visualize parameters in a table.\n",
    "    visualize_params(model.get_params())\n",
    "    \n",
    "    # Display confusion matrix.\n",
    "    visualize_heatmap(y_test, testing_model, 'MLP Classifier')       \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptron_Model(X_train, y_train, X_test, y_test, max_iter):\n",
    "    \n",
    "    model = Perceptron(max_iter = max_iter)\n",
    "    classifier = model.fit(X_train, y_train)\n",
    "    testing_model = model.predict(X_test)\n",
    "    score = accuracy_score(y_test, testing_model)\n",
    "    cv_scores = cross_val_score(classifier, X_test, y_test, cv = 3)\n",
    "\n",
    "    print(' ')\n",
    "    print('===== Perceptron Model =====')\n",
    "    print('score:', score)\n",
    "    print('cross validation scores:', cv_scores)\n",
    "    \n",
    "    # Visualize parameters in a table.\n",
    "    visualize_params(model.get_params())\n",
    "    \n",
    "    # Display confusion matrix.\n",
    "    visualize_heatmap(y_test, testing_model, 'Perceptron Model')    \n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class My_Perceptron:\n",
    "\n",
    "    def __init__(self, t):\n",
    "        \n",
    "        # t is the target y.\n",
    "        self.t = t\n",
    "        \n",
    "    def get_params(self):\n",
    "        \n",
    "        # To report parameters in a table, they must be in a dictionary.\n",
    "        params = {\n",
    "            'bias (b)': b,\n",
    "            'learning rate (r)': r,\n",
    "            'max_iter': max_iter\n",
    "        }\n",
    "        \n",
    "    def fit(self, X, y, b=1.0, r=0.1, max_iter=200):\n",
    "        \n",
    "        # Initialize weights.\n",
    "        self.w = np.random.rand(784,)\n",
    "        \n",
    "        # Store bias.\n",
    "        self.b = b\n",
    "        \n",
    "        for h in range(max_iter):\n",
    "\n",
    "            for i in range(len(X)):\n",
    "                \n",
    "                if y[i] != self.t:\n",
    "                    continue\n",
    "                \n",
    "                z = self.w@X[i] + b\n",
    "                \n",
    "                if math.isnan(z):\n",
    "                    print('Bad z:', z)\n",
    "                    print('self.w:')\n",
    "                    print(self.w)\n",
    "                    print('samples[' + str(i) + ']:')\n",
    "                    print(X[i])\n",
    "                    continue\n",
    "                    \n",
    "                c = self.t - z\n",
    "                \n",
    "                if abs(c) < 0.00001:\n",
    "                    break\n",
    "                \n",
    "                c = c * r\n",
    "                C = np.ones(784,)\n",
    "                C = C * c\n",
    "                C = C * X[i]\n",
    "                self.w = self.w + C\n",
    "                \n",
    "        return z\n",
    "\n",
    "    def predict(self, x):\n",
    "        \n",
    "        z = self.w@x + self.b\n",
    "        \n",
    "        c = self.t - z\n",
    "        \n",
    "        margin = 0.0\n",
    "        p = 0\n",
    "        \n",
    "        # Calculate the probability with a sigmoid function\n",
    "        # if it is within a margin.\n",
    "        while p == 0:\n",
    "            \n",
    "            margin += 0.1\n",
    "        \n",
    "            if c > margin:\n",
    "                p = 0\n",
    "            elif c < (-1) * margin:\n",
    "                p = 0\n",
    "            else:\n",
    "                s = math.exp(c)/(1 + math.exp(c))\n",
    "                p = 1 - abs(s - 0.5)\n",
    "        \n",
    "        return p\n",
    "    \n",
    "    def score(self, X):\n",
    "        \n",
    "        for i in range(len(X_test)):\n",
    "\n",
    "            # Select the next sample and corresponding label.\n",
    "            sample = X_test[i]\n",
    "            label = y_test[i]\n",
    "\n",
    "            # Initialize predictions.\n",
    "            predictions = np.zeros(10)\n",
    "\n",
    "            # Have each perceptron contribute its probability.\n",
    "            for j in range(10):\n",
    "                predictions[j] = models[j].predict(sample)\n",
    "\n",
    "            # If no predictions were made, then something must be wrong!\n",
    "            if predictions.sum() == 0:\n",
    "                huh += 1\n",
    "            else:\n",
    "                # Select the prediction with the highest probability.\n",
    "                prediction = np.argmax(predictions)\n",
    "                if prediction == label:\n",
    "                    hit += 1\n",
    "                else:\n",
    "                    miss += 1\n",
    "\n",
    "        model_score =  round(hit/(hit + miss), 2)\n",
    "        print('r:', r, 'huh:', huh, 'hit:', hit, 'miss:', miss, 'rate:', model_score)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def My_Perceptron_Model(X_train, y_train, X_test, y_test, max_iter, r=0.0001, b=1.0):\n",
    "    \n",
    "    # To visual parameters in a table, they need to be in a dictionary.\n",
    "    params = {\n",
    "        'learning rate (r)': r,\n",
    "        'bias (b)': b,\n",
    "        'max_iter': max_iter\n",
    "    }\n",
    "\n",
    "    # Perforance counters.\n",
    "    perceptron_score = 0.0\n",
    "    perceptron_count = 0\n",
    "    perceptron_correct = 0\n",
    "\n",
    "    # Create a perceptron for each numerial.\n",
    "    models = []\n",
    "    for i in range(10):\n",
    "        models.append(My_Perceptron(i))\n",
    "\n",
    "    # Set the training rate.\n",
    "    r = 0.001\n",
    "    \n",
    "    for i in range(10):\n",
    "        z = models[i].fit(X_train, y_train, r = r, max_iter = max_iter, b = b)\n",
    "\n",
    "    # Performance counters.\n",
    "    hit = 0\n",
    "    miss = 0\n",
    "    huh = 0\n",
    "    \n",
    "    # These lists are input into the heatmap.\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for i in range(len(X_test)):\n",
    "\n",
    "        # Get a sample and its corresponding label.\n",
    "        sample = X_test[i]\n",
    "        label = y_test[i]\n",
    "\n",
    "        # Initialize predictions.\n",
    "        predictions = np.zeros(10)\n",
    "\n",
    "        for j in range(10):\n",
    "            predictions[j] = models[j].predict(sample)\n",
    "\n",
    "        if predictions.sum() == 0:\n",
    "            # There were no predictions.\n",
    "            # That cannot be correct.\n",
    "            huh += 1\n",
    "        else:\n",
    "            # Select the prediction with the highest probability.\n",
    "            prediction = np.argmax(predictions)\n",
    "            y_true.append(label)\n",
    "            y_pred.append(prediction)\n",
    "            \n",
    "            # Evaluate the prediction.\n",
    "            if prediction == label:\n",
    "                hit += 1\n",
    "            else:\n",
    "                miss += 1\n",
    "\n",
    "    # Calculate model score.\n",
    "    model_score =  round(hit/(hit + miss), 2)\n",
    "    \n",
    "    print(' ')\n",
    "    print('===== My Perceptron Model =====')\n",
    "    print('score:', model_score)\n",
    "    print('hit:', hit, 'miss:', miss, 'rate:', model_score)\n",
    "    \n",
    "    # Visualize parameters in a table.\n",
    "    visualize_params(params)\n",
    "    \n",
    "    # Display confusion matrix.\n",
    "    # Calculate the confustion matrix that compares testing labels\n",
    "    # to predicted labels via a testing model.\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # Determine display context.\n",
    "    rc_context = determine_context()\n",
    "    \n",
    "    # Plot the heatmap using the selected context.\n",
    "    with plt.rc_context(rc_context):  \n",
    "        plt.figure(figsize=(6.0,6.0))\n",
    "        sns.heatmap(cm, square=True, annot=True, cbar=True)\n",
    "        plt.xlabel('Predicted Value')\n",
    "        plt.ylabel('True Value')\n",
    "        plt.title('My Perceptron')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    return model_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_neural_network():\n",
    "    \n",
    "    def __init__(self, target):\n",
    "        \n",
    "        # Define the target number for this neural network.\n",
    "        self.target = target\n",
    "        \n",
    "        # Define the number of rows of activations.\n",
    "        self.number_of_activation_rows = 8\n",
    "        \n",
    "        # Define the number of columns of activations.\n",
    "        self.number_of_activation_columns = 8\n",
    "        \n",
    "        # Define the number of activations.\n",
    "        self.number_of_activations = 64\n",
    "        \n",
    "        # Define the number of pixels in an activation.\n",
    "        self.pixels_per_activation = 9\n",
    "        \n",
    "        # Create random weights from 0 to 1.\n",
    "        weights = np.random.random_sample((self.number_of_activation_rows, \n",
    "                                           self.number_of_activation_columns, \n",
    "                                           self.pixels_per_activation))\n",
    "\n",
    "        # Double the weights from 0 to 2.\n",
    "        weights = weights * 2\n",
    "\n",
    "        # Shift the weights from -1 to 1.\n",
    "        weights = weights - 1\n",
    "\n",
    "        # Scale down by 100, resulting in values -0.01 through 0.01.\n",
    "        weights = weights / 100\n",
    "\n",
    "        # Store the weights in an instance variable.\n",
    "        self.weights = weights\n",
    "\n",
    "    def fit(self, X_train, y_train, learning_rate = 0.01, maximum_iterations = 1000):\n",
    "        '''\n",
    "        Train the model with training samples and labels.\n",
    "        X_train   Samples.  Each sample is a vector of pixel values.\n",
    "        y_train   Labels corresponding to the samples.\n",
    "        learning_rate         Learning rate.\n",
    "        maximum_iterations    Maximum iterations.\n",
    "        '''\n",
    "        samples = X_train.copy()\n",
    "        samples.resize(len(X_train,), 28, 28)\n",
    "        labels = y_train.copy()\n",
    "        \n",
    "        # Process each activation in the 8x8 matrix.\n",
    "        for activation_row in range(self.number_of_activation_rows):\n",
    "            for activation_column in range(self.number_of_activation_columns):\n",
    "                iteration = 0\n",
    "                while iteration < maximum_iterations:\n",
    "                    iteration += 1\n",
    "                    for i in range(len(samples)):\n",
    "                        \n",
    "                        if labels[i] != self.target:\n",
    "                            continue\n",
    "                            \n",
    "                        sample = samples[i]\n",
    "\n",
    "                        # Load the pixel vector for the activation at j and k.\n",
    "                        activation_pixels = np.zeros(self.pixels_per_activation)\n",
    "                        \n",
    "                        # Get the Northwest corner of the activation in the sample.\n",
    "                        sample_row = int((activation_row % 9) * 3)\n",
    "                        sample_column = int((activation_column % 9) * 3)\n",
    "                        \n",
    "                        # Get the pixels from the North edge of the activation\n",
    "                        activation_pixels[0] = sample[sample_row][sample_column]\n",
    "                        activation_pixels[1] = sample[sample_row][sample_column + 1]\n",
    "                        activation_pixels[2] = sample[sample_row][sample_column + 2]\n",
    "                        \n",
    "                        # Get the pixels from the middle row of the activation\n",
    "                        activation_pixels[3] = sample[sample_row + 1][sample_column]\n",
    "                        activation_pixels[4] = sample[sample_row + 1][sample_column + 1]\n",
    "                        activation_pixels[5] = sample[sample_row + 1][sample_column + 2]\n",
    "                        \n",
    "                        # Get the pixels from the South edge of the activation.\n",
    "                        activation_pixels[6] = sample[sample_row + 2][sample_column]\n",
    "                        activation_pixels[7] = sample[sample_row + 2][sample_column + 1]\n",
    "                        activation_pixels[8] = sample[sample_row + 2][sample_column + 2]\n",
    "\n",
    "                        # A value of 1 is added to move off the origin.\n",
    "                        activation_pixels = activation_pixels + 1\n",
    "                        \n",
    "                        # Calculate dot product of weights and pixels.\n",
    "                        weights = self.weights[activation_row][activation_column]\n",
    "                        \n",
    "                        # Calculate the activation value.\n",
    "                        activation = weights @ activation_pixels\n",
    "\n",
    "                        # Calculate the cost.  A bias of 10 is added to move off the origin.\n",
    "                        cost = self.target + 10 - activation\n",
    "\n",
    "                        weights = weights + cost * learning_rate * activation_pixels\n",
    "                        \n",
    "                        self.weights[activation_row][activation_column] = weights\n",
    "        return \n",
    "\n",
    "\n",
    "    def get_probability(self, target):\n",
    "        '''\n",
    "        Return the probability is that the result of the target is the target \n",
    "        of this neural network.\n",
    "        '''\n",
    "        sample = target.copy()\n",
    "        sample.resize(28, 28)\n",
    "        \n",
    "        votes = np.zeros((8,8))\n",
    "\n",
    "        # Process all samples for each of the activations.\n",
    "        for activation_row in range(self.number_of_activation_rows):\n",
    "            for activation_column in range(self.number_of_activation_columns):\n",
    "\n",
    "                # Load pixel vector.\n",
    "                activation_pixels = np.zeros(self.pixels_per_activation)\n",
    "                sample_row = int((activation_row % 9) * 3)\n",
    "                sample_column = int((activation_column % 9) * 3)\n",
    "                \n",
    "                # Get the pixel values from the North edge of the activation.\n",
    "                activation_pixels[0] = sample[sample_row][sample_column]\n",
    "                activation_pixels[1] = sample[sample_row][sample_column + 1]\n",
    "                activation_pixels[2] = sample[sample_row][sample_column + 2]\n",
    "                \n",
    "                # Get the pixel values from the middle row of the activation\n",
    "                activation_pixels[3] = sample[sample_row + 1][sample_column]\n",
    "                activation_pixels[4] = sample[sample_row + 1][sample_column + 1]\n",
    "                activation_pixels[5] = sample[sample_row + 1][sample_column + 2]\n",
    "                \n",
    "                # Get the pixel values from the South edge of the activation.\n",
    "                activation_pixels[6] = sample[sample_row + 2][sample_column]\n",
    "                activation_pixels[7] = sample[sample_row + 2][sample_column + 1]\n",
    "                activation_pixels[8] = sample[sample_row + 2][sample_column + 2]\n",
    "                \n",
    "                # Add 1 to move off the origin.\n",
    "                activation_pixels = activation_pixels + 1\n",
    "                \n",
    "                weights = self.weights[activation_row][activation_column]\n",
    "\n",
    "                # Calculate dot product of weights and pixels.\n",
    "                activation = weights @ activation_pixels\n",
    "                activation = round(activation)\n",
    "                \n",
    "                # If the target is for this neural network, vote for it.\n",
    "                if activation == self.target + 10:\n",
    "                    votes[activation_row][activation_column] += 1\n",
    "                              \n",
    "        # Return the probability that the target is for this neural network.\n",
    "        probability = np.average(votes)\n",
    "#         print(' ')\n",
    "#         print('===== debug =====')\n",
    "#         print('self.target:', self.target)\n",
    "#         print('Votes:')\n",
    "#         for i in range(8):\n",
    "#             print(votes[i])\n",
    "        \n",
    "#         if self.target == 1 or self.target == 3:\n",
    "#             probability = probability * 0.8\n",
    "        \n",
    "        return probability\n",
    "        \n",
    "\n",
    "    def get_score(self, X_test, y_test):\n",
    "        '''\n",
    "        Calculate the rate of correct decisions given trained weights.\n",
    "        '''\n",
    "        # Define scoring counters.\n",
    "        count = 0\n",
    "        correct = 0\n",
    "        false_positives = 0\n",
    "        false_negatives = 0\n",
    "        true_positives = 0\n",
    "        true_negatives = 0\n",
    "        \n",
    "        samples = X_test.copy()\n",
    "        samples.resize(len(X_test), 28, 28)\n",
    "        labels = y_test.copy()\n",
    "        \n",
    "        # Make a decision for each sample\n",
    "        for i in range(len(samples)):\n",
    "            \n",
    "            sample = samples[i]\n",
    "            label = labels[i]\n",
    "            \n",
    "            count += 1\n",
    "            \n",
    "            probability = self.get_probability(sample)\n",
    "            if False:\n",
    "                print(' ')\n",
    "                print('probability:', probability)\n",
    "            \n",
    "            if self.target == label:\n",
    "                if probability == 1.0:\n",
    "                    correct += 1\n",
    "                    true_positives += 1\n",
    "                    if False:  \n",
    "                        print(' ')\n",
    "                        print('self.target:', self.target, 'true positive')\n",
    "                        print(' ')\n",
    "                else:\n",
    "                    false_negatives += 1\n",
    "                    if False:  \n",
    "                        print('self.target:', self.target, \n",
    "                              'false negative:', label, \n",
    "                              'probability:', probability)\n",
    "            else:\n",
    "                if probability == 1.0:\n",
    "                    false_positives += 1\n",
    "                    if False:  \n",
    "                        print('self.target:', self.target, \n",
    "                              'false positive:', label,\n",
    "                              'probability:', probability)\n",
    "                else:\n",
    "                    correct += 1\n",
    "                    true_negatives += 1\n",
    "                    if False:  \n",
    "                        print(' ')\n",
    "                        print('self.target:', self.target, 'true negative')\n",
    "                        print(' ')\n",
    "\n",
    "        # Return the score.\n",
    "        score = {\n",
    "            'count': count,\n",
    "            'correct': correct,\n",
    "            'false_positives': false_positives,\n",
    "            'false_negatives': false_negatives,\n",
    "            'true_positives': true_positives,\n",
    "            'true_negatives': true_negatives\n",
    "        }\n",
    "        \n",
    "        return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_neural_network_model(X_train, y_train, X_test, y_test, \n",
    "                            learning_rate = 0.01, \n",
    "                            probability_weights = np.ones((10)),\n",
    "                            maximum_iterations = 1001):\n",
    "    \n",
    "    print(' ')\n",
    "    print('===== My Neural Network Model =====')\n",
    "    \n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'maximum_iterations': maximum_iterations\n",
    "    }\n",
    "\n",
    "    total_count = 0\n",
    "    total_correct = 0\n",
    "    total_false_positives = 0\n",
    "    total_false_negatives = 0\n",
    "    total_true_positives = 0\n",
    "    total_true_negatives = 0\n",
    "    \n",
    "    \n",
    "    neural_networks = []\n",
    "    \n",
    "    for i in range(10):\n",
    "    \n",
    "        # instantiate model\n",
    "        neural_network = my_neural_network(i)\n",
    "        neural_networks.append(neural_network)\n",
    "\n",
    "        # Train model.\n",
    "        print('Training neural network for digit '+ str(i) + '.')\n",
    "        neural_network.fit(X_train, y_train, \n",
    "                           learning_rate = learning_rate, \n",
    "                           maximum_iterations = maximum_iterations)\n",
    "\n",
    "        if False:\n",
    "            # Test model.\n",
    "            print('Scoring neural network for digit ' + str(i) + '.')\n",
    "\n",
    "            score = neural_network.get_score(X_train, y_train)\n",
    "            count = score['count']\n",
    "            correct = score['correct']\n",
    "            false_positives = score['false_positives']\n",
    "            false_negatives = score['false_negatives']\n",
    "            true_positives = score['true_positives']\n",
    "            true_negatives = score['true_negatives']\n",
    "\n",
    "            if False:\n",
    "                print('\\t count:', count, 'correct:', correct, 'rate:', round(correct/count, 2))\n",
    "                print('\\t true positives:', true_positives, round(true_positives/count, 2))\n",
    "                print('\\t false negatives:', false_negatives, round(false_negatives/count, 2))\n",
    "                print(' ')\n",
    "                print('\\t true negatives:', true_negatives, round(true_negatives/count, 2))\n",
    "                print('\\t false positives:', false_positives, round(false_positives/count, 2))\n",
    "\n",
    "            total_count += count\n",
    "            total_correct += correct\n",
    "            total_false_positives += false_positives\n",
    "            total_false_negatives += false_negatives\n",
    "            total_true_positives += true_positives\n",
    "            total_true_negatives += true_negatives\n",
    "\n",
    "        if False:\n",
    "            print('\\n Totals for all digits:')\n",
    "            print('\\t count:', total_count, 'correct:', total_correct, 'rate:', \n",
    "                  round(total_correct/total_count, 2))\n",
    "            print('\\t true positives:', total_true_positives, round(total_true_positives/total_count, 2))\n",
    "            print('\\t false negatives:', total_false_negatives, round(total_false_negatives/total_count, 2))\n",
    "            print(' ')\n",
    "            print('\\t true negatives:', total_true_negatives, round(total_true_negatives/total_count, 2))\n",
    "            print('\\t false positives:', total_false_positives, round(total_false_positives/total_count, 2))\n",
    "    \n",
    "     # Visualize parameters in a table.\n",
    "    visualize_params(params)\n",
    "\n",
    "    # Display confusion matrix.\n",
    "    # Calculate the confustion matrix that compares testing labels\n",
    "    # to predicted labels via a testing model.\n",
    "    y_true = []; y_pred = []  \n",
    "    samples = X_test.copy()\n",
    "    labels = y_test.copy()\n",
    "    \n",
    "    total_correct = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    # Select the highest probability for the sample.\n",
    "    # The index of the highest probabilty will be the prediction for the digit.\n",
    "    for i in range(len(samples)):\n",
    "        \n",
    "        y_true.append(labels[i])\n",
    "        \n",
    "        probabilities = np.zeros((10))\n",
    "        \n",
    "        for j in range(10):\n",
    "            probabilities[j] = neural_networks[j].get_probability(samples[i])\n",
    "            \n",
    "        probabilities = probabilities * probability_weights\n",
    "                \n",
    "        if False:\n",
    "            print('probabilities:', probabilities)\n",
    "    \n",
    "        if np.sum(probabilities) == 0:\n",
    "            print('Error.  No probabilities were offered.')\n",
    "            y_pred.append(0)\n",
    "        else:\n",
    "            y_pred.append(np.argmax(probabilities))\n",
    "        \n",
    "    # Calculate the rate.\n",
    "    for i in range(len(y_true)):\n",
    "        total_count += 1\n",
    "        if y_true[i] == y_pred[i]:\n",
    "            total_correct += 1\n",
    "            s = 'Boffo!'\n",
    "        else:\n",
    "            s = ' '\n",
    "        if False:\n",
    "            print('i:', i, 'y_true:', y_true[i], 'y_pred', y_pred[i], s)\n",
    "            \n",
    "    total_rate = round(total_correct / total_count, 2)\n",
    "    print('total_count:', total_count, 'total_correct:', total_correct, 'total_rate:', total_rate)\n",
    "        \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Determine display context.\n",
    "    rc_context = determine_context()\n",
    "\n",
    "    # Plot the heatmap using the selected context.\n",
    "    with plt.rc_context(rc_context):  \n",
    "        plt.figure(figsize=(6.0,6.0))\n",
    "        sns.heatmap(cm, square=True, annot=True, cbar=True)\n",
    "        plt.xlabel('Predicted Value')\n",
    "        plt.ylabel('True Value')\n",
    "        plt.title('My Neural Network')\n",
    "        plt.show()                \n",
    "\n",
    "                \n",
    "    return total_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# main\n",
    "\n",
    "if True:\n",
    "    preamble()\n",
    "    \n",
    "# Global Variables\n",
    "global_face_color = (0.18, 0.31, 0.32)\n",
    "global_text_color = \"yellow\"\n",
    "    \n",
    "# Maximum of iterations for any model that iterates.\n",
    "max_iter = 1001\n",
    "\n",
    "# Tabulate the model scores.\n",
    "model_scores = {\n",
    "    \"Gaussian Mixture\":0.0,\n",
    "    \"Gaussian Naive Bayes\":0.0,\n",
    "    \"Decision Tree\":0.0,\n",
    "    \"MLP Classifier\":0.0,\n",
    "    \"k-Neighbors\":0.0,\n",
    "    \"Perceptron\":0.0,\n",
    "    \"My Perceptron\":0.0,\n",
    "    \"My Neural Network\":0.0}\n",
    "\n",
    "# Visualize a sample of images.\n",
    "if True:\n",
    "    visualize_images()\n",
    "\n",
    "if True:\n",
    "    # Loading samples and corresponding labels.\n",
    "    print(' ')\n",
    "    print('Loading testing samples and labels.')\n",
    "    file_name = 'train.csv'\n",
    "    skip_header = 1\n",
    "    max_rows = 1000\n",
    "    test_size = 0.25\n",
    "    X_train, X_test, y_train, y_test = load_data(file_name, skip_header, max_rows, test_size)\n",
    "    \n",
    "    # Display training data.\n",
    "    print(' ')\n",
    "    print('Training Data')\n",
    "    types_of_figures = np.zeros((10))\n",
    "    for i in range(len(y_train)):\n",
    "        types_of_figures[y_train[i]] += 1\n",
    "    for i in range(10):\n",
    "        print('i:', i, 'count:', round(types_of_figures[i], 0))\n",
    "        \n",
    "    # Display testing data.\n",
    "    print(' ')\n",
    "    print('Testing Data')\n",
    "    types_of_figures = np.zeros((10))\n",
    "    for i in range(len(y_test)):\n",
    "        types_of_figures[y_test[i]] += 1\n",
    "    for i in range(10):\n",
    "        print('i:', i, 'count:', round(types_of_figures[i], 0))\n",
    "        \n",
    "if True:\n",
    "    # Visualize all digits in a two-dimentsional isomap.\n",
    "    isomap_for_all_digits(X_train, y_train)\n",
    "\n",
    "if True:\n",
    "    model_score = Gaussian_Mixture_Model(X_train, y_train, X_test, y_test, max_iter)\n",
    "    model_scores[\"Gaussian Mixture\"] = model_score\n",
    "    \n",
    "if True:\n",
    "    model_score = Gaussian_Naive_Bayes_Model(X_train, y_train, X_test, y_test)\n",
    "    model_scores[\"Gaussian Naive Bayes\"] = model_score\n",
    "    \n",
    "if True:\n",
    "    model_score = Decision_Tree_Model(X_train, y_train, X_test, y_test)\n",
    "    model_scores[\"Decision Tree\"] = model_score\n",
    "    \n",
    "if True:\n",
    "    model_score = KNeighbors_Model(X_train, y_train, X_test, y_test)\n",
    "    model_scores[\"k-Neighbors\"] = model_score\n",
    "    \n",
    "if True:\n",
    "    model_score = MLPClassifier_Model(X_train, y_train, X_test, y_test, max_iter)\n",
    "    model_scores[\"MLP Classifier\"] = model_score\n",
    "    \n",
    "if True:\n",
    "    model_score = Perceptron_Model(X_train, y_train, X_test, y_test, max_iter)\n",
    "    model_scores[\"Perceptron\"] = model_score\n",
    "    \n",
    "if True:\n",
    "    model_score = My_Perceptron_Model(X_train, y_train, X_test, y_test, max_iter)\n",
    "    model_scores[\"My Perceptron\"] = model_score\n",
    "    \n",
    "if True:   \n",
    "    learning_rate = 0.001\n",
    "    maximum_iterations = max_iter\n",
    "    probability_weights = np.ones((10))\n",
    "    probability_weights[1] = 0.8\n",
    "    probability_weights[2] = 1.1\n",
    "    probability_weights[5] = 1.1\n",
    "    probability_weights[8] = 1.0\n",
    "    model_score = my_neural_network_model(X_train, y_train, X_test, y_test, \n",
    "                                          learning_rate = learning_rate, \n",
    "                                          probability_weights = probability_weights,\n",
    "                                          maximum_iterations = maximum_iterations)    \n",
    "    model_scores[\"My Neural Network\"] = model_score\n",
    "            \n",
    "if True:\n",
    "    visualize_model_scores(model_scores)\n",
    "    \n",
    "print(' ')\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
