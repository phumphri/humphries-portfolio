{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import statistics\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preamble():\n",
    "    print(' ')\n",
    "    print('Perceptron Learning Algorithm')\n",
    "    print('Patrick Humphries (pvhumphr@usc.edu)')\n",
    "    print('University of Southern California')\n",
    "    print('INF 552 Machine Learning for Data Science (32458)')\n",
    "    print('Programming Assignment 4')\n",
    "    print('Spring 2020')\n",
    "    print(' ')\n",
    "    print('Due to the large amount of data that was provided')\n",
    "    print('please wait for the first graphic to display.')\n",
    "    print('Canceling the current graphic will allow the next')\n",
    "    print('graphic to be displayed.')\n",
    "    print(' ')\n",
    "    print('The process for maximizing accuracy and minimizing')\n",
    "    print('weight change takes nearly 10,000 iterations.  ')\n",
    "    print('Progress is displayed for every 1,000 iterations.')\n",
    "    print('When the program is done, \"Done!\" will be displayed.')\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    '''\n",
    "    Load the attributes into vector X, which contains three columns,\n",
    "    one for each column in the input file.\n",
    "    \n",
    "    Load the labels from the fourth column into vector L.\n",
    "    \n",
    "    Create the weight vector containing all zeroes as W.\n",
    "    \n",
    "    Return X, L, and W.\n",
    "    '''\n",
    "    # Define the coordinates training dataset.\n",
    "    X = []\n",
    "    \n",
    "    # Define the labels training dataset.\n",
    "    L = []\n",
    "    \n",
    "    # Create file reference.\n",
    "    rows = open(\"classification.txt\", \"r\")\n",
    "    \n",
    "    # Define limits for unit testing.\n",
    "    row_number = 0\n",
    "    row_limit = 100000\n",
    "    \n",
    "    # Define control totals.\n",
    "    negative_values = 0\n",
    "    positive_values = 0\n",
    "    total_values = 0\n",
    "    \n",
    "    # Process the input file.\n",
    "    for row in rows:\n",
    "        row = row.strip()\n",
    "        fields = row.split(',')\n",
    "        \n",
    "        # Add a set a coordinates to the coordinates training dataset.\n",
    "        x = []\n",
    "        x.append(float(fields[0]))\n",
    "        x.append(float(fields[1]))\n",
    "        x.append(float(fields[2]))\n",
    "        X.append(x)\n",
    "        \n",
    "        # Add the corresponding label to the labels training dataset.\n",
    "        l = int(fields[3])\n",
    "        L.append(l)\n",
    "        \n",
    "        # Update control totals.\n",
    "        if l < 0:\n",
    "            negative_values += 1\n",
    "        else:\n",
    "            positive_values += 1\n",
    "        total_values += 1\n",
    "        \n",
    "        # Limit the number of rows for the training data.\n",
    "        row_number += 1\n",
    "        if row_number > row_limit:\n",
    "            break\n",
    "    \n",
    "    # Convert to vectors.\n",
    "    X = np.array(X)\n",
    "    L = np.array(L)\n",
    "    \n",
    "    # Create a vector for the weights.\n",
    "    W = np.zeros(3)\n",
    "    \n",
    "    # Display control totals.\n",
    "    print('Negative Values:', negative_values, round((negative_values/total_values),2))\n",
    "    print('Positive Values:', positive_values, round((positive_values/total_values),2))\n",
    "    print('Total Values:', total_values)\n",
    "    \n",
    "    # Return the input data and corresponding lables.\n",
    "    return (X,L,W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_3d(X,L,title):\n",
    "    '''\n",
    "    Plot a scatter plot with three-dimensional coordinates in\n",
    "    each row of the training dataset (X).\n",
    "    \n",
    "    Set the color of each datapoint based on the entries in the\n",
    "    label dataset (L).  Blue for negative values and red for positive.\n",
    "    '''\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d', alpha=0.5)\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    i = 0\n",
    "    for dimensions in X:   \n",
    "        \n",
    "        x = dimensions[0]\n",
    "        y = dimensions[1]\n",
    "        z = dimensions[2]\n",
    "        \n",
    "        if L[i] < 0:\n",
    "            ax.scatter(x, y, z, color='b')\n",
    "        else:\n",
    "            ax.scatter(x, y, z, color='r')\n",
    "            \n",
    "        i += 1\n",
    "        \n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_2d(X,L,a,b):\n",
    "    '''\n",
    "    Create a two-dimensional scatter plot using two of the three\n",
    "    dimensions of the training data (X). \n",
    "    \n",
    "    The color of the data point will be determined by the label\n",
    "    in the label dataset (L).  Blue for negative labels and red\n",
    "    for positive labels.\n",
    "    \n",
    "    Parameters \"a\" and \"b\" specify which two of the three dimensions\n",
    "    to use.\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        x = X[i]\n",
    "        if L[i] < 0:\n",
    "            ax.scatter(x[a], x[b], c='b')\n",
    "        else:\n",
    "            ax.scatter(x[a], x[b], c='r')\n",
    "            \n",
    "    ax.set_title('Column ' + str(a) + ' vs. Column ' + str(b))\n",
    "\n",
    "    # This is used in Jupyter Notebook while using the \"monokai\" theme\n",
    "    # so the labels are visible.\n",
    "    if False:\n",
    "        fig.savefig(\"test.png\")\n",
    "        image = mpimg.imread(\"test.png\")\n",
    "        plt.imshow(image)\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(plot_parameters):\n",
    "    from scipy.stats import norm\n",
    "    \n",
    "    # Define constants.\n",
    "    mu_n = plot_parameters[\"negatives\"][\"mean\"]\n",
    "    sigma_n = plot_parameters[\"negatives\"][\"sigma\"]\n",
    "    x1_n = plot_parameters[\"negatives\"][\"min\"]\n",
    "    x2_n= plot_parameters[\"negatives\"][\"max\"]\n",
    "    \n",
    "    mu_p = plot_parameters[\"positives\"][\"mean\"]\n",
    "    sigma_p = plot_parameters[\"positives\"][\"sigma\"]\n",
    "    x1_p = plot_parameters[\"positives\"][\"min\"]\n",
    "    x2_p= plot_parameters[\"positives\"][\"max\"]\n",
    "    \n",
    "    dp = plot_parameters[\"decision point\"]\n",
    "    \n",
    "    s = 'Negative: ' + str(round(mu_n,4)) + ', Decision: ' \\\n",
    "        + str(round(dp, 4)) + ', Positive: ' + str(round(mu_p,4))  \n",
    "    print(' ')\n",
    "    print('Negatives:')\n",
    "    print('\\tMean:', round(mu_n, 4))\n",
    "    print('\\tSigma:', round(sigma_n, 4))\n",
    "    print('\\tMin:', round(x1_n, 4))\n",
    "    print('\\tMax:', round(x2_n, 4))\n",
    "    print(' ')\n",
    "    print('Positives:')\n",
    "    print('\\tMean:', round(mu_p, 4))\n",
    "    print('\\tSigma:', round(sigma_p, 4))\n",
    "    print('\\tMin:', round(x1_p, 4))\n",
    "    print('\\tMax:', round(x2_p, 4))\n",
    "    print(' ')\n",
    "    print('Decision Point:', round(dp, 4))\n",
    "    \n",
    "    # Calculate the z-transforms.\n",
    "    z1_n = (x1_n - mu_n) / sigma_n\n",
    "    z2_n = (x2_n - mu_n) / sigma_n\n",
    "    \n",
    "    z1_p = (x1_p - mu_p) / sigma_p\n",
    "    z2_p = (x2_p - mu_p) / sigma_p\n",
    "    \n",
    "    # Range of x in specification.\n",
    "    x_n = np.arange(z1_n, z2_n, 0.001)\n",
    "    \n",
    "    x_p = np.arange(z1_p, z2_p, 0.001)\n",
    "    \n",
    "    # Entire range of x, both in and out of speicification.\n",
    "    x_all = np.arange(-2, 2, 0.001)\n",
    "    \n",
    "    # Calculate probability.\n",
    "    y_n = norm.pdf(x_n, mu_n, 1)\n",
    "    y2_n = norm.pdf(x_all, mu_n, 1)\n",
    "    \n",
    "    y_p = norm.pdf(x_p, mu_p, 1)\n",
    "    y2_p = norm.pdf(x_all, mu_p, 1)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    \n",
    "    ax.plot(x_all, y2_n, c='blue')\n",
    "    ax.plot(x_all, y2_p, c='red')\n",
    "    ax.plot([dp,dp],[0,0.5])\n",
    "    \n",
    "    ax.set_title(s)\n",
    "\n",
    "    # This is used in Jupyter Notebook while using the \"monokai\" theme\n",
    "    # so the labels are visible.\n",
    "    if False:\n",
    "        fig.savefig(\"test.png\")\n",
    "        image = mpimg.imread(\"test.png\")\n",
    "        plt.imshow(image)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sklearn_perceptron():\n",
    "    from sklearn.datasets import load_digits\n",
    "    from sklearn.linear_model import Perceptron\n",
    "    X, y = load_digits(return_X_y=True)\n",
    "    clf = Perceptron(tol=1e-3, random_state=0)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    print(' ')\n",
    "    print('sklearn perceptron')\n",
    "    print('clf.score(X, y):', clf.score(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model(X,L,W,I,R,O):\n",
    "    '''\n",
    "    Use training data (X) and labels (L) to refine weights (W)\n",
    "    until there is no change in weights or the limit of \n",
    "    iterations (I) is reached.  The learning rate is R.\n",
    "    '''\n",
    "    print(' ')\n",
    "    print('Calculating Model')\n",
    "    print('\\tIterations:', I)\n",
    "    print('\\tLearning Rate:', R)\n",
    "    print('\\tOverfitting:', O)\n",
    "    print(' ')\n",
    "    # Used in messages and limiting processing.\n",
    "    iteration = 0\n",
    "    \n",
    "    # The labels are -1 and +1.  The bias changes that to 0 and 2,\n",
    "    # positive numbers.\n",
    "    bias = 0\n",
    "    \n",
    "    # This vector contains the weights from a previous iteration.\n",
    "    W1 = np.zeros(W.shape)\n",
    "    \n",
    "    # Values for plotting prediction are contained here.\n",
    "    plot_parameters = {}\n",
    "\n",
    "    # Iterate until there is no more changes to the weights.\n",
    "    for iteration in range(I):\n",
    "        for i in range(len(X)):\n",
    "            \n",
    "            # Get a set of cordinates.\n",
    "            x = X[i]\n",
    "            \n",
    "            # Get the corresponding label.\n",
    "            # Add a bias so the labels are positive.\n",
    "            l = L[i] + bias\n",
    "            \n",
    "            # Make a prediction by multiply each coordinate by its weight\n",
    "            # and summing the results.\n",
    "            y = x @ W\n",
    "            \n",
    "            # Find the difference between the label and the prediction.\n",
    "            d = l - y\n",
    "            \n",
    "            # Adjust the weight using the learning rate and difference\n",
    "            # between the prediction and the label.\n",
    "            for j in range(len(W)):\n",
    "                W[j] = W[j] + R * d * x[j]\n",
    "\n",
    "        # Calculate decision point assumming Gaussian distribution.\n",
    "        negatives = []\n",
    "        positives = []\n",
    "        i = 0\n",
    "        for x in X:\n",
    "            y = x @ W\n",
    "            if L[i] < 0:\n",
    "                negatives.append(y)\n",
    "            else:\n",
    "                positives.append(y)\n",
    "            i += 1\n",
    "\n",
    "        len_negatives = len(negatives)\n",
    "        sum_negatives = sum(negatives)\n",
    "        min_negatives = min(negatives)\n",
    "        max_negatives = max(negatives)\n",
    "        avg_negatives = sum_negatives / len_negatives\n",
    "        std_negatives = statistics.stdev(negatives)\n",
    "\n",
    "        plot_parameters[\"negatives\"] = {}\n",
    "        plot_parameters[\"negatives\"][\"min\"] = min_negatives\n",
    "        plot_parameters[\"negatives\"][\"max\"] = max_negatives\n",
    "        plot_parameters[\"negatives\"][\"mean\"] = avg_negatives\n",
    "        plot_parameters[\"negatives\"][\"sigma\"] = std_negatives\n",
    "\n",
    "        len_positives = len(positives)\n",
    "        sum_positives = sum(positives)\n",
    "        min_positives = min(positives)\n",
    "        max_positives = max(positives)\n",
    "        avg_positives = sum_positives / len_positives\n",
    "        std_positives = statistics.stdev(positives)\n",
    "\n",
    "        plot_parameters[\"positives\"] = {}\n",
    "        plot_parameters[\"positives\"][\"min\"] = min_positives\n",
    "        plot_parameters[\"positives\"][\"max\"] = max_positives\n",
    "        plot_parameters[\"positives\"][\"mean\"] = avg_positives\n",
    "        plot_parameters[\"positives\"][\"sigma\"] = std_positives\n",
    "        \n",
    "        if O == 0:\n",
    "            decision_point = 0\n",
    "        elif O == 1:\n",
    "            # Find the intersection of the two Gaussian curves.\n",
    "            # This actually resulted in lower accuracy.\n",
    "            # https://stackoverflow.com/questions/22579434/python-finding-the-intersection-point-of-two-gaussian-curves\n",
    "            m1 = avg_negatives\n",
    "            m2 = avg_positives\n",
    "            std1 = std_negatives\n",
    "            std2 = std_positives\n",
    "            a = 1/(2*std1**2) - 1/(2*std2**2)\n",
    "            b = m2/(std2**2) - m1/(std1**2)\n",
    "            c = m1**2 /(2*std1**2) - m2**2 / (2*std2**2) - np.log(std2/std1)\n",
    "            d = np.roots([a,b,c])\n",
    "            decision_point = d[1]\n",
    "        elif O == 2:\n",
    "            # The decision point is the stepping function.\n",
    "            # It is the average of the negative mean plus one\n",
    "            # standard diviation plus the positive mean less one\n",
    "            # standard diviation.  This is needed because of\n",
    "            # the fuzzy plane between negative and positive labels.\n",
    "            decision_point = avg_negatives + std_negatives\n",
    "            decision_point += avg_positives - std_positives\n",
    "            decision_point /= 2\n",
    "        else:\n",
    "            decision_point = 0\n",
    "        \n",
    "        # Add the decision point so it can be plotted.\n",
    "        plot_parameters[\"decision point\"] = decision_point\n",
    "\n",
    "        #  Make predictions using the decision point.\n",
    "        accuary = 0.0\n",
    "        count = 0\n",
    "        correct = 0\n",
    "        i = 0\n",
    "        for x in X:\n",
    "            count += 1\n",
    "            y = x @ W\n",
    "            if y < decision_point:\n",
    "                prediction = -1\n",
    "            else:\n",
    "                prediction = +1\n",
    "            if prediction == L[i]:\n",
    "                correct += 1\n",
    "            i += 1\n",
    "            \n",
    "        # Calculate accuracy.\n",
    "        accuracy = correct / count\n",
    "\n",
    "        # Display progress.\n",
    "        if iteration % 100 == 0 or iteration > I - 10:\n",
    "            print('Iteration:', iteration, 'Accuracy:', accuracy, 'Weights:', W)\n",
    "        \n",
    "        # When there is no change in weights, quit.\n",
    "        if np.equal(W,W1).all():\n",
    "            print(' ')\n",
    "            print('Break:  No change in weights.')\n",
    "            print('Iteration:', iteration, 'Accuracy:', accuracy, 'Weights:', W)\n",
    "            break\n",
    "        else:\n",
    "            # Update the previous weights with the current weights.\n",
    "            W1 = np.copy(W)\n",
    "            \n",
    "    # Plot distribution.\n",
    "    plot_results(plot_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# main:  All processing is controlled here.\n",
    "\n",
    "# Print identification data.\n",
    "if True:\n",
    "    preamble()\n",
    "\n",
    "# Load training data and initialize differences.\n",
    "(X,L,W) = load_data()\n",
    "\n",
    "# Check visually if the data could be bifurcated.\n",
    "if True:\n",
    "    title = 'Sanity Check:  There are two regions of label values.'\n",
    "    plot_data_3d(X,L,title)\n",
    "    plot_data_2d(X,L,0,1)\n",
    "    plot_data_2d(X,L,0,2)\n",
    "    plot_data_2d(X,L,1,2)\n",
    "\n",
    "# Calculate the weights.\n",
    "# X:  Training data.\n",
    "# L:  Training labels.\n",
    "# W:  Weights.\n",
    "# I:  Maximum iterations allowed.\n",
    "# R:  Learning Rate\n",
    "# O:  Overfitting (Decision Points at zero, intersection, average)\n",
    "I = 10001\n",
    "R = 0.0001\n",
    "O = 0\n",
    "calculate_model(X,L,W,I,R,O)\n",
    "\n",
    "# Run the sklearn.linear_model.Perceptron package.\n",
    "if True:\n",
    "    sklearn_perceptron()\n",
    "\n",
    "print(' ')\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
